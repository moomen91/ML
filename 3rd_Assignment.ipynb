{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Foundations of Mahicne Learning\n",
    "## 3rd_Assignment -- Moamin Abdulkareem\n",
    "## Analyzing breast cancer dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from csv import reader\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset using csv_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading the dataset\n",
    "# I will use csv reader to load the dataset\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    f = open(filename,'r')\n",
    "    \n",
    "    csv_reader = reader(f)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        if not row:\n",
    "            continue\n",
    "        dataset.append(row)\n",
    "        \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Features_MC.csv'\n",
    "dataset = load_csv(file)\n",
    "data_array = np.asarray(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing ID attributes from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_irrelevant_features(x):\n",
    "\n",
    "    # here we delete the attributes of ids which we have to remove before any computation\n",
    "    # and also the first row which is the names of the attributes is also going to be removed\n",
    "\n",
    "    x = np.delete(x, 0, axis=1)  # first column which is ID\n",
    "    x = np.delete(x, 1, axis=1)  # third column which is sampleID\n",
    "    x = np.delete(x, 1, axis=1)  #forth column which is microID\n",
    "    features = x[0,:]\n",
    "    x = np.delete(x, 0, axis=0)  # features names which is the first row\n",
    "\n",
    "    return x, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function on our dataset\n",
    "\n",
    "data_array, features_vector = delete_irrelevant_features(data_array)\n",
    "\n",
    "# features vector without class values\n",
    "\n",
    "features_vector = features_vector[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(x):\n",
    "\n",
    "    # replacing the missing values with the mean of the column\n",
    "    # first of all we will put nan values instead of question mark\n",
    "    # then we take the mean of the each column to replace the missing values by it\n",
    "\n",
    "    for row in x:\n",
    "\n",
    "        for i in range(len(row)):\n",
    "\n",
    "            try:\n",
    "                float(row[i])\n",
    "\n",
    "            except ValueError:\n",
    "\n",
    "                row[i] = np.NaN\n",
    "\n",
    "    x = x.astype(float)\n",
    "\n",
    "    # this function takes the mean of each column without considering the nan values\n",
    "    \n",
    "    columns_means = np.nanmean(x, axis=0) \n",
    "    \n",
    "    # getting the indices of the nan values\n",
    "    \n",
    "    inds = np.where(np.isnan(x)) \n",
    "\n",
    "    # filling the missing values for the mean of each column that we calculated in the list of columns means\n",
    "    \n",
    "    x[inds] = np.take(columns_means, inds[1]) \n",
    "\n",
    "    return x\n",
    "\n",
    "data_array = fill_missing_values(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def  binarize_class_values(x):\n",
    "\n",
    "    lb = preprocessing.LabelBinarizer() # I imported the labelBinarizer to change the class values to binary\n",
    "    classes = lb.fit_transform(x[:,0])  # the class values in the dataset is the first column\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        x[i][0] = classes[i]\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_array = binarize_class_values(data_array)\n",
    "\n",
    "x = data_array[:,1:]# this is the dataset without class values\n",
    "\n",
    "y = data_array[:,0] # this is the class labels or the targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting and visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  2211\n",
      "Number of testing examples:  1474\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f137e5daa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Splitting the data into training and testing i.e. 60% goes for training and 40% for testing'''\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.4)\n",
    "\n",
    "print(\"Number of training examples: \",X_train.shape[0])\n",
    "print(\"Number of testing examples: \",X_test.shape[0])\n",
    "\n",
    "# visualize the dataset using histogram\n",
    "labels = ['Malignant', 'Benign']\n",
    "\n",
    "population = [np.sum(y==0), np.sum(y)]\n",
    "y_pos = np.arange(len(labels))\n",
    "barlist = plt.bar(y_pos, population, align='center',width=0.5)\n",
    "plt.xticks(y_pos, labels)\n",
    "plt.ylabel('Number of examples')\n",
    "plt.title('Breast Cancer Dataset')\n",
    "barlist[0].set_color('r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scaling the dataset using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on test set using logistic regression:  0.20420624151967434\n"
     ]
    }
   ],
   "source": [
    "'''We have to define a threshold which will be used to predict the output of the labels\n",
    "and if the probability was greater than the threshold then the label is assigned to 1 otherwise 0'''\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Applying the model on the training data\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "predicted_labels = model.predict(X_test_scaled) > threshold\n",
    "\n",
    "\n",
    "print(\"Error on test set using logistic regression: \" ,mean_squared_error(y_true=Y_test, y_pred= predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting cross validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ECV(X,y,classifier,num_folds):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    kf.get_n_splits(X_scaled)\n",
    "    \n",
    "    \n",
    "    Ens = list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        \n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = classifier\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_predicted = clf.predict(x_test)\n",
    "        accuracy_test = mean_squared_error(y_pred=y_predicted, y_true=y_test)\n",
    "        Ens.append(accuracy_test)\n",
    "        \n",
    "    ECV = sum(Ens) / num_folds\n",
    "    \n",
    "    return ECV, Ens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27100271002710025, 0.26287262872628725, 0.5636856368563685, 0.056910569105691054, 0.2682926829268293, 0.09510869565217392, 0.07880434782608696, 0.4945652173913043, 0.9619565217391305, 0.33152173913043476]\n",
      "Average cross validation error using logistic regression:  0.33847207493814063\n"
     ]
    }
   ],
   "source": [
    "cross_val_error_LR, EN = get_ECV(x, y,classifier = LogisticRegression(), num_folds=10)\n",
    "print(EN)\n",
    "print(\"Average cross validation error using logistic regression: \",cross_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation error using Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2899728997289973, 0.6747967479674797, 0.4146341463414634, 0.032520325203252036, 0.34417344173441733, 0.4076086956521739, 0.07336956521739131, 0.5081521739130435, 0.842391304347826, 0.5054347826086957]\n",
      "Average cross validation error using Multi-layer perceptron:  0.40930540827147405\n"
     ]
    }
   ],
   "source": [
    "cross_val_error_MLP, ENs = get_ECV(x,y, classifier=tree.DecisionTreeClassifier(), num_folds=10)\n",
    "print(ENs)\n",
    "print(\"Average cross validation error using Multi-layer perceptron: \", cross_val_error_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting selected attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 selected features that contribute the most in the prediction using Logistic regression:  [' x', ' rmean', ' rstd', ' b1mean', ' surfovervol', 'Sum Average', 'SRE', 'RP', 'HGRE', 'Complexity']\n"
     ]
    }
   ],
   "source": [
    "'''Getting the 10 most important features in the dataset based on Logistic Regression '''\n",
    "rfe = RFE(LogisticRegression(),10)\n",
    "\n",
    "rfe.fit(X_train_scaled,Y_train)\n",
    "\n",
    "\n",
    "selected_features = [features_vector[i] for i in range(len(features_vector)) if rfe.ranking_[i] == 1]\n",
    "\n",
    "# Extracting the indices of the selected features which in this case has a rank of 1 in the rfe.ranking_ vector\n",
    "# And then by using these indices we can get our features\n",
    "\n",
    "print(\"The 10 selected features that contribute the most in the prediction using Logistic regression: \",selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
